{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaf7af9-06fa-4c42-aa0b-4dbf4a253e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.stats import beta,norm\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d580c2c2-9731-4ab1-b010-17cb8e5b2bdc",
   "metadata": {},
   "source": [
    "## generate synthetic forecast/observed data\n",
    "\n",
    "The python function synth_data will generate sythetic forecasts (continuous/probability and binary) and observations (binary) that have some degree of correlation (rhoxf) between them and also allow the user to control the forecast bias and sharpness (distribution of the forecast values). A bivariate normal distribution is generated with specified correlation, the resulting dummy variables are used to generate observations by finding the threshold that will produce the desired base rate (xbar = mean observation), as well as using a copula approach to convert the forecasts to a beta distribution with specified alpha/beta parameters that produce the desired mean and variance (sharp * observed variance). The continuous forecast array is also thresholded to produce binary forecasts with the desired mean forecast (fbar).\n",
    "\n",
    "python functions cont_table and cont_table_counts are discussed in intro_2x2_table.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1a1e02-07e1-4868-b20f-baf6647db76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_data(nn,xbar,fbar,sharp,rhoxf):\n",
    "    # generate synthetic binary obs with base rate = xbar\n",
    "    # generate synthetic forecasts [continuous beta-distributed probability-like]\n",
    "    # generate synthetic forecasts [binary with mean forecast = fbar]\n",
    "    # rhoxf controls the correlation of the bivariate normal that is used to generate obs and fcst-beta\n",
    "    # sharp controls the normalized sharpness in determining the beta distribution parameters of the fcsts\n",
    "    cov = np.array([[1.,rhoxf ], [rhoxf,1.]])\n",
    "    pts = rng.multivariate_normal([0., 0.], cov, size=nn)\n",
    "    obs_bin=np.zeros_like(pts[:,0])\n",
    "    xthresh=norm.ppf(1-xbar,0.,1.)\n",
    "    obs_bin[pts[:,0]>=xthresh]=1.\n",
    "    sx21=xbar*(1.-xbar)\n",
    "    sf21=sharp*sx21\n",
    "    nu1=fbar*(1-fbar)/sf21-1.\n",
    "    alpha1=fbar*nu1\n",
    "    beta1=(1.-fbar)*nu1\n",
    "    fcst_beta=beta.ppf(norm.cdf(pts[:,1],0.,1.), alpha1,beta1)\n",
    "    fthresh=np.quantile(fcst_beta,1.-fbar)\n",
    "    fcst_bin=fcst_beta>=fthresh\n",
    "    return obs_bin,fcst_beta,fcst_bin\n",
    "\n",
    "def cont_table(fcst,obs):\n",
    "    # assuming fcst and obs are both binary and are of the same length\n",
    "    # joint probabilities elelements should sum to 1\n",
    "    # return elements of 2x2 contingency table as well as a pandas dataframe for easy viewing\n",
    "    nn=float(len(obs))\n",
    "    aa=np.sum(obs*fcst)/nn\n",
    "    bb=np.sum((1.-obs)*fcst)/nn\n",
    "    cc=np.sum(obs*(1.-fcst))/nn\n",
    "    dd=np.sum((1.-obs)*(1.-fcst))/nn\n",
    "    df=pd.DataFrame(data=np.array([[aa,bb,aa+bb],[cc,dd,cc+dd],[aa+cc,bb+dd,aa+bb+cc+dd]]),index=['fcst=yes','fcst=no','col sum'],columns=['obs=yes','obs=no','row sum'])\n",
    "    return aa, bb, cc, dd, df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2520b244-b73a-4836-a511-a5e8e9cdfbf3",
   "metadata": {},
   "source": [
    "## example - Finley's 1884 experimental tornado forecasts\n",
    "\n",
    "The values in the following cell will generate a large sample of data with similar performance characteristics as Finley's 1884 tornado forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79cb0aa-63d8-468f-b485-eff4319db709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these values will generate a large sample of data with similar performance characteristics as Finley's 1884 tornado forecasts\n",
    "nn=100000\n",
    "xbar=0.0182\n",
    "fbar=0.0357\n",
    "rhoxf=0.77\n",
    "ratio=0.2\n",
    "\n",
    "obs_pts,fcst_pts,fcst_bin=synth_data(nn,xbar,fbar,ratio,rhoxf)\n",
    "\n",
    "aa, bb, cc, dd, df_tbl = cont_table(fcst_bin,obs_pts)\n",
    "\n",
    "# multiply by 2803 to get similar total counts as Finley\n",
    "print(df_tbl*2803.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2698eca0-b45a-47ba-a07b-adca2aa02fb1",
   "metadata": {},
   "source": [
    "## discrimination diagram\n",
    "\n",
    "Plotting the conditional forecast distributions, conditioning on the observed value ($p[f|x=0]$ and $p[f|x=1]$) is known as a discrimination diagram. A good forecast system will show large separation between conditional forecast distribution given $obs=yes$ (green histogram below) and the conditional forecast distribution given $obs=no$ (grey histogram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ce0f7-c5ef-4e1f-b3f0-a0cdf3e6a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the discrimination diagram\n",
    "\n",
    "# calculate some stats\n",
    "xbar_pts=np.mean(obs_pts)\n",
    "sx2_pts=np.var(obs_pts,ddof=0)\n",
    "sf2_pts=np.var(fcst_pts,ddof=0)\n",
    "rho_pts=np.corrcoef([obs_pts,fcst_pts])[0][1]\n",
    "sf_sx=np.sqrt(sf2_pts)/np.sqrt(sx2_pts)\n",
    "\n",
    "# format strings containing these stats in the diagram title\n",
    "leg1=r' $\\rho$' + f' = {np.round(rho_pts,2)}'\n",
    "sharp=r' $s_f$/$s_x$' + f' = {np.round(sf_sx,2)}'\n",
    "tit1=r'$\\bar x$'+f' = {np.round(xbar_pts,3)}'\n",
    "\n",
    "fig,axs=plt.subplots(figsize=(6,4))\n",
    "\n",
    "# obs=yes conditional distribution\n",
    "axs.hist(fcst_pts[obs_pts>=0.5], bins=41,color='green',density=True,label='fcst[obs=yes]',alpha=.5)\n",
    "# obs=no conditional distribution\n",
    "axs.hist(fcst_pts[obs_pts<0.5], bins=41,color='gray',density=True,label='fcst[obs=no]',alpha=.5)\n",
    "axs.set_title(tit1+leg1+sharp)\n",
    "axs.set_xlabel('fcst')\n",
    "axs.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a99f8af-2947-4338-a7fe-d801b52b883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the location of the fcst threshold that was used to generate the array of binary forecasts from the continuous array\n",
    "\n",
    "fthresh=np.quantile(fcst_pts,1.-fbar)\n",
    "\n",
    "fig,axs=plt.subplots(figsize=(6,4))\n",
    "\n",
    "# obs=yes conditional distribution\n",
    "axs.hist(fcst_pts[obs_pts>=0.5], bins=41,color='green',density=True,label='fcst[obs=yes]',alpha=.5)\n",
    "# obs=no conditional distribution\n",
    "axs.hist(fcst_pts[obs_pts<0.5], bins=41,color='gray',density=True,label='fcst[obs=no]',alpha=.5)\n",
    "axs.plot([fthresh,fthresh],[0,40],'k--',lw=0.7)\n",
    "axs.set_title(tit1+leg1+sharp)\n",
    "axs.set_xlabel('fcst')\n",
    "axs.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7880c-9480-4f42-ae6e-256bb29319a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print some common measures from 2x2 table, more python functions at the end of this notebook and intro_2x2_table.ipynb\n",
    "\n",
    "def pod(a,b,c,d):\n",
    "    return a/(a+c)\n",
    "    \n",
    "def sr(a,b,c,d):\n",
    "    return a/(a+b)    \n",
    "\n",
    "def pofd(a,b,c,d):\n",
    "    return b/(b+d)\n",
    "    \n",
    "def csi(a,b,c,d):\n",
    "    return a/(a+b+c)\n",
    "\n",
    "print('POD = ',pod(aa,bb,cc,dd))\n",
    "print('SR = ',sr(aa,bb,cc,dd))\n",
    "print('POFD = ',pofd(aa,bb,cc,dd))\n",
    "print('CSI = ',csi(aa,bb,cc,dd))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3902a74-bbf6-46d1-86b7-fee266715900",
   "metadata": {},
   "source": [
    "## generate ROC curve and performance diagram\n",
    "\n",
    "By systematically varying the forecast threshold from low to high across the range of forecast values and generating corresponding 2x2 contingency tables, we can produce arrays of measures such as POD, SR, and POFD as a function of the forecast threshold. A ROC curve is generated by plotting POD vs POFD, and a performance diagram is generated by plotting POD vs SR\n",
    "\n",
    "The following function will return the elements of the 2x2 contingency table corresponding to a list of forecast thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe62dce-4479-41ea-b6fc-13141d76e04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_2x2_table(fcst,obs,thresholds):\n",
    "    # assuming fcst and obs are of the same length, fcst are continuous and obs are binary\n",
    "    # loop over thresholds and find elements of 2x2 contingency table for each\n",
    "    # return these in a pandas dataframe\n",
    "    nthresh=len(thresholds)\n",
    "    aa=np.full(nthresh,np.nan)\n",
    "    bb=np.full(nthresh,np.nan)\n",
    "    cc=np.full(nthresh,np.nan)\n",
    "    dd=np.full(nthresh,np.nan)\n",
    "    for j in np.arange(nthresh):\n",
    "        fthresh=thresholds[j]\n",
    "        fcst_bin=fcst>=fthresh\n",
    "        nn=float(len(obs))\n",
    "        aa[j]=np.sum(obs*fcst_bin)/nn\n",
    "        bb[j]=np.sum((1.-obs)*fcst_bin)/nn\n",
    "        cc[j]=np.sum(obs*(1.-fcst_bin))/nn\n",
    "        dd[j]=np.sum((1.-obs)*(1.-fcst_bin))/nn\n",
    "    df=pd.DataFrame(data=np.array([thresholds,aa,bb,cc,dd]).T,columns=['thresh','a','b','c','d'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba542b5-3f09-4351-864e-efd0685c77d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up array of thresholds going from zero to slightly above the max forecast value\n",
    "# this will produce PODs that vary from 1 to 0, POFDs that vary from 1 to 0\n",
    "# SR at the zero threshold will equal xbar, SR when POD=POFD=0 is undefined since a=b=0\n",
    "threshs=np.quantile(fcst_pts,np.linspace(0.001,0.999,99))\n",
    "threshs=np.insert(threshs,0,0.)\n",
    "threshs=np.append(threshs,np.max(fcst_pts)*1.01)\n",
    "\n",
    "# generate arrays of 2x2 contingency table elements corresponding with these thresholds\n",
    "df = calc_2x2_table(fcst_pts,obs_pts,threshs)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b18bcce-d36a-4af4-abe8-ad78f34c23f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ROC and performance diagrams\n",
    "\n",
    "xbar=0.0182\n",
    "\n",
    "fig, axs = plt.subplots(1, 2,figsize=(12,6))\n",
    "axs = axs.flat\n",
    "\n",
    "# arrays hold 2d fields of POD, POFD, SR to allow for calculation of scores in background of plots\n",
    "pod1=np.arange(0.001,1.0,0.001)\n",
    "sr1=np.arange(0.001,1.0,0.001)\n",
    "pofd1=np.arange(0.001,1.0,0.001)\n",
    "\n",
    "sr2,pod2=np.meshgrid(sr1,pod1)\n",
    "pofd_roc,pod_roc=np.meshgrid(pofd1,pod1)\n",
    "\n",
    "\n",
    "# 2x2 contingency elements in POD,SR space\n",
    "aa_r=xbar*pod2\n",
    "bb_r=xbar*(pod2/sr2-pod2)\n",
    "cc_r=xbar*(1.-pod2)\n",
    "dd_r=1.-xbar*(pod2/sr2+1.-pod2)\n",
    "\n",
    "# typical performance diagram will plot frequency bias and CSI in the background since these are simple functions of POD, SR\n",
    "bias_roebber=pod2/sr2\n",
    "plot_roebber=csi(aa_r,bb_r,cc_r,dd_r)\n",
    "\n",
    "label1=r'$CSI$'\n",
    "extend1='neither'\n",
    "d_lvls=np.linspace(0.,1.,21)\n",
    "d_ticks=np.linspace(0.,1.,11)\n",
    "\n",
    "# plot performance diagram\n",
    "sc1=axs[1].contourf(sr1,pod1,plot_roebber,levels=d_lvls,cmap='RdGy_r',extend=extend1)\n",
    "cs0=axs[1].contour(sr1,pod1,bias_roebber,levels=np.array([0.1,0.25,0.5,0.75,1.,1.33,2.,4.,10.]),colors='k',linestyles='dashed',linewidths=0.7)\n",
    "axs[1].clabel(cs0, cs0.levels, inline=True, fontsize=8)\n",
    "plt.colorbar(sc1,orientation='vertical',shrink=0.735,label=label1,ax=axs[1],ticks=d_ticks)\n",
    "axs[1].set_aspect('equal')\n",
    "axs[1].set_ylim(0.,1.)\n",
    "axs[1].set_xlim(0.,1.)\n",
    "axs[1].set_xlabel('SR')\n",
    "axs[1].set_ylabel('POD')\n",
    "axs[1].set_title('Performance diagram ')\n",
    "\n",
    "# plot ROC diagram\n",
    "label1=r\"$d'$\"\n",
    "extend1='max'\n",
    "d_lvls=np.linspace(0.,4.,17)\n",
    "d_ticks=np.linspace(0.,4.,9)\n",
    "def dprime(a,b,c,d):\n",
    "    return norm.ppf(a/(a+c))-norm.ppf(b/(b+d))\n",
    "    \n",
    "# 2x2 contingency elements in POD,POFD space\n",
    "aa_roc=xbar*pod_roc\n",
    "bb_roc=(1-xbar)*pofd_roc\n",
    "cc_roc=xbar*(1.-pod_roc)\n",
    "dd_roc=(1-xbar)*(1.-pofd_roc)\n",
    "\n",
    "# set no skill region to nan\n",
    "aa_roc[pod_roc<pofd_roc]=np.nan\n",
    "bb_roc[pod_roc<pofd_roc]=np.nan\n",
    "cc_roc[pod_roc<pofd_roc]=np.nan\n",
    "dd_roc[pod_roc<pofd_roc]=np.nan\n",
    "\n",
    "# plot ROC diagram with background score = d'\n",
    "\n",
    "sc0=axs[0].contourf(pofd1,pod1,dprime(aa_roc,bb_roc,cc_roc,dd_roc),levels=d_lvls,cmap='RdGy_r',extend=extend1)\n",
    "plt.colorbar(sc0,orientation='vertical',shrink=0.735,label=label1,ax=axs[0],ticks=d_ticks)\n",
    "\n",
    "#zero skill line\n",
    "axs[0].plot([0,1],[0,1],'k--',lw=2)\n",
    "axs[0].set_aspect('equal')\n",
    "axs[0].set_ylim(0.,1.)\n",
    "axs[0].set_xlim(0.,1.)\n",
    "axs[0].set_xlabel('POFD')\n",
    "axs[0].set_ylabel('POD')\n",
    "axs[0].set_title('ROC diagram ')\n",
    "\n",
    "\n",
    "# plot results - POD vs POFD on ROC, POD vs SR on performance diagram\n",
    "df['POD']=pod(df.a,df.b,df.c,df.d)\n",
    "df['POFD']=pofd(df.a,df.b,df.c,df.d)\n",
    "df['SR']=sr(df.a,df.b,df.c,df.d)\n",
    "axs[0].plot(df.POFD,df.POD,lw=2)\n",
    "axs[1].plot(df.SR,df.POD,lw=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef40546-bfb0-4ea7-ace7-84d3179d5ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synthetic 2-D observation forecast binary field generator\n",
    "\n",
    "# colors\n",
    "colorlist=['xkcd:fire engine red','xkcd:violet','xkcd:water blue','xkcd:medium green']\n",
    "\n",
    "# seeds for random number generators\n",
    "obs_rng = np.random.default_rng(10987654321)\n",
    "fcst_rng = np.random.default_rng(42)\n",
    "\n",
    "def make_regions(noise, sigma, prob):\n",
    "    filtered = gaussian_filter(noise, sigma, mode='reflect')\n",
    "    threshold = np.quantile(filtered, 1 - prob)\n",
    "    return (filtered > threshold).astype('float')\n",
    "\n",
    "def generate_obs_field(size, sigma, prob, rng=obs_rng):\n",
    "    noise = rng.random(size)    \n",
    "    return noise, make_regions(noise, sigma, prob)\n",
    "\n",
    "def generate_forecast_field(truth_noise, sigma, prob, noise_weight, rng=obs_rng):\n",
    "    noise = rng.random(truth_noise.shape)\n",
    "    noise = noise_weight * noise + (1 - noise_weight) * truth_noise\n",
    "    return make_regions(noise, sigma, prob)\n",
    "\n",
    "# generate obs field with a moderate level of autocorrelation\n",
    "obs_sigma = 3.\n",
    "\n",
    "# generate a \"skillful/smooth\" forecast field with a higher level of compactness\n",
    "skillfcst_sigma=6.\n",
    "skill_error_weight=0.5\n",
    "\n",
    "# generate a \"random/spiky\" forecast field with a low level of compactness\n",
    "randfcst_sigma=1.\n",
    "rand_error_weight=1.0\n",
    "\n",
    "# specify base rate and bias\n",
    "base_rate = 0.1\n",
    "bias=1.\n",
    "\n",
    "# domain size\n",
    "ni, nj = 333, 333\n",
    "\n",
    "# generate fields\n",
    "obs_noise, obs = generate_obs_field((nj, ni), obs_sigma, base_rate)\n",
    "skill_fcst = generate_forecast_field(obs_noise, skillfcst_sigma, bias*base_rate, noise_weight=skill_error_weight, rng=fcst_rng)\n",
    "rand_fcst = generate_forecast_field(obs_noise, randfcst_sigma, bias*base_rate, noise_weight=rand_error_weight, rng=fcst_rng)\n",
    "\n",
    "# calculate CSI\n",
    "skill_csi=np.sum(obs*skill_fcst)/(np.sum(obs)+np.sum(skill_fcst)-np.sum(obs*skill_fcst))\n",
    "rand_csi=np.sum(obs*rand_fcst)/(np.sum(obs)+np.sum(skill_fcst)-np.sum(obs*rand_fcst))\n",
    "skill_pod=np.sum(obs*skill_fcst)/np.sum(obs)\n",
    "rand_pod=np.sum(obs*rand_fcst)/np.sum(obs)\n",
    "\n",
    "# plot these fields\n",
    "fig,ax = plt.subplots(1,3,figsize=(15,6))\n",
    "axs=ax.flat\n",
    "\n",
    "cmap_obs=colors.ListedColormap(['white',colorlist[0]])\n",
    "axs[0].imshow(obs, cmap=cmap_obs, origin='lower')\n",
    "axs[0].set_title(r'synthetic obs $\\bar x$ = '+f'{base_rate}')\n",
    "\n",
    "cmap_fcst=colors.ListedColormap(['white',colorlist[1]])\n",
    "axs[1].imshow(skill_fcst, cmap=cmap_fcst, origin='lower')\n",
    "axs[1].set_title(r'skillful/smooth fcst $CSI$ = '+f'{np.round(skill_csi,2)} $POD$ = '+f'{np.round(skill_pod,2)}')\n",
    "\n",
    "cmap_rand=colors.ListedColormap(['white',colorlist[2]])\n",
    "axs[2].imshow(rand_fcst, cmap=cmap_rand, origin='lower')\n",
    "axs[2].set_title(r'random/spiky fcst $CSI$ = '+f'{np.round(rand_csi,2)} $POD$ = '+f'{np.round(rand_pod,2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d65ca-157f-4c59-90bb-0057128dceda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up functions for score calculations from 2x2 contingency table\n",
    "def ang2bias(x):\n",
    "    return np.tan(x*np.pi/180.)\n",
    "\n",
    "def bias2ang(x):\n",
    "    return np.arctan(x)*180./np.pi\n",
    "\n",
    "def pod(a,b,c,d):\n",
    "    return a/(a+c)\n",
    "    \n",
    "def sr(a,b,c,d):\n",
    "    return a/(a+b)    \n",
    "\n",
    "def pofd(a,b,c,d):\n",
    "    return b/(b+d)\n",
    "    \n",
    "def mr(a,b,c,d):\n",
    "    return c/(c+d)\n",
    "\n",
    "def csi(a,b,c,d):\n",
    "    return a/(a+b+c)\n",
    "\n",
    "def tversky(a,b,c,d,gamma):\n",
    "    return a/(a+gamma*b+(1.-gamma)*c)\n",
    "    \n",
    "def pss(a,b,c,d):\n",
    "    return (a*d-b*c)/(a+c)/(b+d)\n",
    "\n",
    "def css(a,b,c,d):\n",
    "    return (a*d-b*c)/(a+b)/(c+d)\n",
    "\n",
    "def qyule(a,b,c,d):\n",
    "    return (a*d-b*c)/(a*d+b*c)\n",
    "\n",
    "def mse(a,b,c,d):\n",
    "    return b+c\n",
    "    \n",
    "def srskill(a,b,c,d):\n",
    "    return (a*d-b*c)/(a+b)/(b+d)\n",
    "    \n",
    "def podskill(a,b,c,d):\n",
    "    return (a*d-b*c)/(a+c)/(c+d)\n",
    "    \n",
    "def deelia(a,b,c,d):\n",
    "    return np.log(b/(a+b))/np.log(a/(a+c))\n",
    "\n",
    "def edi(a,b,c,d):\n",
    "    return (np.log(b/(b+d))-np.log(a/(a+c)))/(np.log(b/(b+d))+np.log(a/(a+c)))\n",
    "\n",
    "def sedi(a,b,c,d):\n",
    "    return (np.log(b/(b+d))-np.log(a/(a+c))-np.log(d/(b+d))+np.log(c/(a+c)))/(np.log(b/(b+d))+np.log(a/(a+c))+np.log(d/(b+d))+np.log(c/(a+c)))\n",
    "\n",
    "def hss(a,b,c,d):\n",
    "    return 2.*(a*d-b*c)/((a+c)*(c+d)+(a+b)*(b+d))\n",
    "\n",
    "def kappa(a,b,c,d,w):\n",
    "    return (a*d-b*c)/((1.-w)*(a+c)*(c+d)+w*(a+b)*(b+d))\n",
    "\n",
    "def dprime(a,b,c,d):\n",
    "    return norm.ppf(a/(a+c))-norm.ppf(b/(b+d))\n",
    "\n",
    "def biasodds(a,b,c,d):\n",
    "    return (a+b)*(b+d)/(a+c)/(c+d)\n",
    "\n",
    "def oddsr(a,b,c,d):\n",
    "    return a*d/b/c\n",
    "\n",
    "def bias(a,b,c,d):\n",
    "    return (a+b)/(a+c)\n",
    "    \n",
    "def phi(a,b,c,d):\n",
    "    return (a*d-b*c)/np.sqrt((a+c)*(c+d)*(a+b)*(b+d))\n",
    "\n",
    "def relvalue(a,b,c,d,alpha,xbar):\n",
    "    if alpha>xbar:\n",
    "        relval=((1.-alpha)*a-alpha*b)/(1.-alpha)/xbar\n",
    "    else:\n",
    "        relval=(alpha*d-(1.-alpha)*c)/alpha/(1.-xbar)\n",
    "    return relval\n",
    "\n",
    "def betafa(a,b,c,d):\n",
    "    return (a/(a+c))/(b/(b+d))\n",
    "    \n",
    "def betame(a,b,c,d):\n",
    "    return (d/(b+d))/(c/(a+c))\n",
    "\n",
    "def alphafa(a,b,c,d):\n",
    "    return (a/(a+c))/(a/(a+c)+b/(b+d))\n",
    "    \n",
    "def alphame(a,b,c,d):\n",
    "    return (c/(a+c))/(d/(b+d)+c/(a+c))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a180aa-bb16-4164-8d39-94c7a54b2fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
